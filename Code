# CKME136_Final-Results
library(psych)
library(dplyr)
library(party)
library(ggplot2)
library(gmodels)
library(caret)
library(class)
library(pROC)
library(kernlab)
library(plotROC)
library(randomForest)
library(caretEnsemble)
library(RColorBrewer)
library(reshape2)
library(DMwR)
library(ROSE)
library(e1071)
library(gridExtra)
#read the data:
mydata <- read.csv('file:///C:/Users/Ariel/Documents/census-us.csv')

#Looking into the data:
str(mydata)
ggplot(mydata,aes(x=salary,fill=salary))+geom_bar(aes(stat='identity'))+ggplot2::annotate(geom = 'text',label="24,720\n 75%",x=1,y=20000,color='white',size=12)+ggtitle('Target Attribute Distribution')+ggplot2::annotate(geom = 'text',x=2,y=5000,label='7,841\n 25%',,color='white',size=12)+theme(legend.text = element_text(size = 15),legend.title = element_text(size = 22),plot.title = element_text(size = 28,hjust = 0.5))+scale_fill_manual(values = c('#4C5B5C','#FF715B'))

#Isolating the rows with the value "?" in the occupation variable.
unknown_occupation <- mydata[mydata$occupation==" ?",]
mydata_clean <- mydata[mydata$occupation !=" ?",]
# before splitting the occupation into "blue collar" and "white collar" for fitting the tree, checking the proportion of the salary variable in both cases in order to see where the rows with the "?" value belong.
CrossTable(mydata_clean$salary,format = 'SPSS')
CrossTable(unknown_occupation$salary,format = 'SPSS')
#the proportions of the salary below 50,000 is a lot bigger among the missing values dataset than in the main dataset, therefore I will assume that these cases are "blue collar"
#adding a new variable, "occupation_group", in which I split the different occupations into the two categories, "white collar", and "blue collar".
mydata$occupation_group <- as.factor(ifelse(mydata$occupation==" Armed-Forces"|
                                              mydata$occupation==" Craft-repair"|
                                              mydata$occupation==" Farming-fishing"|
                                              mydata$occupation==" Handlers-cleaners"|
                                              mydata$occupation==" Machine-op-inspct"|
                                              mydata$occupation== " Other-service"|
                                              mydata$occupation==" Priv-house-serv"|
                                              mydata$occupation==" Protective-serv"|
                                              mydata$occupation == " ?" |
                                              mydata$occupation==" Transport-moving",
                                            "Blue Collar","White Collar"))

#Checking the frequency of the two categories, the dataset appears to be well balanced:
CrossTable(mydata$occupation_group,format = 'SPSS')
ggplot(mydata,aes(x=occupation_group,fill=occupation_group))+geom_bar(aes(stat='identity'))+ggplot2::annotate(geom = 'text',label="16,007\n 49.1%",x=1,y=16000,color='white',size=16)+ggplot6::annotate(geom = 'text',x=6,y=16000,label='16,554\n 50.9%',,color='white',size=16)+scale_fill_manual(values = c('#6C4144','#C57B57'))+theme(legend.text = element_text(size = 15),legend.title = element_text(size = 18))+scale_fill_manual(values = c('#4C5B5C','#FF715B'))

#Fitting the tree:
tree_model <- ctree(salary ~ ., data = subset(mydata, select = - c(education,occupation,relationship)),controls = ctree_control(minbucket = 1000,minsplit = 1000))
plot(tree_model)

# Aggregating marital status into a binary feature, as per the decision tree.
mydata$marital.binary <- ifelse(mydata$marital.status==" Divorced" | 
                                  mydata$marital.status==" Married-spouse-absent" |
                                  mydata$marital.status==" Never-married" |
                                  mydata$marital.status== " Separated" |
                                  mydata$marital.status==  " Widowed", 0,1)

# Aggregating occupation_group into a binary feature
mydata$occupation.binary <- ifelse(mydata$occupation_group=="Blue Collar",0,1)
#Sex
mydata$sex.male <- ifelse(mydata$sex==" Male",1,0)

# Splitting the data into 3 parts for train, test ans validation:
set.seed(46)
ind <- sample(x=c(1:3),size = nrow(mydata),replace = T,prob = c(0.07,0.63,0.3))
ValidationSet <- mydata[ind==1,]
TrainingSet <- mydata[ind==2,]
TestSet <- mydata[ind==3,]
TrainingSet$salary.num <- factor(ifelse(TrainingSet$salary==" >50K",'X.1','X.0'))
TestSet$salary.num <- factor(ifelse(TestSet$salary==" >50K",'X.1','X.0'))
ValidationSet$salary.num <- factor(ifelse(ValidationSet$salary==" >50K",'X.1','X.0'))

##Checking the target feature distribution in the three datasets, to make sure that it is faithful derivative of the full set:
TestSet2 <- TestSet %>%
  select(salary) 


TrainingSet2 <- TrainingSet %>%
  select(salary)


ValidationSet2 <- ValidationSet %>%
  select(salary) 

TestSetPlot <- ggplot(data = TestSet2,aes(x=salary,fill=salary))+geom_bar()+labs(title='Distribution of Target Feature in the Test Set')+theme(plot.title = element_text(hjust = 0.5,size = 20))+scale_fill_manual(values = c('#4C5B5C','#FF715B'))+annotate(geom = 'text',label='75.3%',x=1,y=5000,color='white',size=9)+annotate(geom = 'text',label='24.9%',x=2,y=1000,color='white',size=9)
TrainingSetPlot <- ggplot(data = TrainingSet2,aes(x=salary,fill=salary))+geom_bar()+labs(title='Distribution of Target Feature in the Training Set')+theme(plot.title = element_text(hjust = 0.5,size = 20))+scale_fill_manual(values = c('#4C5B5C','#FF715B'))+annotate(geom = 'text',label='76.3%',x=1,y=6500,color='white',size=9)+annotate(geom = 'text',label='23.6%',x=2,y=2000,color='white',size=9)
ValidationSetPlot <- ggplot(data = ValidationSet2,aes(x=salary,fill=salary))+geom_bar()+labs(title='Distribution of Target Feature in the Validation Set')+theme(plot.title = element_text(hjust = 0.5,size = 20))+scale_fill_manual(values = c('#4C5B5C','#FF715B'))+annotate(geom = 'text',label='74.9%',x=1,y=800,color='white',size=9)+annotate(geom = 'text',label='25.1%',x=2,y=200,color='white',size=9)
gridExtra::grid.arrange(TestSetPlot,TrainingSetPlot,ValidationSetPlot)

# Normalize function

normalize <- function(x){
  return((x-min(x)) / (max(x)-min(x)))
}

# Normalized Sets:
TrainingSet.Norm <- normalize(TrainingSet[,c(1,4,12,16,17,18)])
TrainingSet.Norm$salary.num <- factor(ifelse(TrainingSet$salary==" >50K",'X.1','X.0'))
TestSet.Norm <- normalize(TestSet[,c(1,4,12,16,17,18)])
TestSet.Norm$salary.num <- factor(ifelse(TestSet$salary==" >50K",'X.1','X.0'))
ValidationSet.Norm <- normalize(ValidationSet[,c(1,4,12,16,17,18)])
ValidationSet.Norm$salary.num <- factor(ifelse(ValidationSet$salary==" >50K",'X.1','X.0'))

# the formula interface for the machine
f = as.formula(salary.num ~ Age+education.num+hours.per.week+marital.binary+occupation.binary+sex.male)




###SVM

# control w/o cross-validation:

ctrl2 <- trainControl(method = 'none',classProbs = TRUE,summaryFunction = twoClassSummary,savePredictions = TRUE)

#cost:0.01
set.seed(2)
grid001 <- data.frame(.C=0.01,.sigma=0.14)
tune.svm0.01 <- train(f,data = TrainingSet.Norm,method='svmRadial',scaled=FALSE,trControl=ctrl2,tuneGrid=grid001)
pred.svm0.01 <- predict(tune.svm0.01,ValidationSet.Norm,type='prob')
roc.svm0.01 <- roc(pred.svm0.01$X.0,response = ValidationSet.Norm$salary.num)
roc.svm0.01$auc
df.svm0.01 <- data.frame(prob=pred.svm0.01$X.0,COST='0.01 / auc = 0.851',obs=ValidationSet.Norm$salary.num)

#cost:0.1
set.seed(2)
grid01 <- data.frame(.C=0.1,.sigma=0.14)
tune.svm0.1 <- train(f,data = TrainingSet.Norm,method='svmRadial',scaled=FALSE,trControl=ctrl2,tuneGrid=grid01)
pred.svm0.1 <- predict(tune.svm0.1,ValidationSet.Norm,type='prob')
roc.svm0.1 <- roc(pred.svm0.1$X.0,response = ValidationSet.Norm$salary.num)
roc.svm0.1$auc
df.svm0.1 <- data.frame(prob=pred.svm0.1$X.0,COST='0.1 / auc = 0.857',obs=ValidationSet.Norm$salary.num)

#cost:1
set.seed(2)
grid1 <- data.frame(.C=1,.sigma=0.14)
tune.svm1 <- train(f,data = TrainingSet.Norm,method='svmRadial',scaled=FALSE,trControl=ctrl2,tuneGrid=grid1)
pred.svm1 <- predict(tune.svm1,ValidationSet.Norm,type='prob')
roc.svm1 <- roc(pred.svm1$X.0,response = ValidationSet.Norm$salary.num)
roc.svm1$auc
df.svm1 <- data.frame(prob=pred.svm1$X.0,COST='1 / auc = 0.858',obs=ValidationSet.Norm$salary.num)

#cost:10
set.seed(2)
grid10 <- data.frame(.C=10,.sigma=0.14)
tune.svm10 <- train(f,data = TrainingSet.Norm,method='svmRadial',scaled=FALSE,trControl=ctrl2,tuneGrid=grid10)
pred.svm10 <- predict(tune.svm10,ValidationSet.Norm,type='prob')
roc.svm10 <- roc(pred.svm10$X.0,response = ValidationSet.Norm$salary.num)
roc.svm10$auc
df.svm10 <- data.frame(prob=pred.svm10$X.0,COST='10 / auc = 0.864',obs=ValidationSet.Norm$salary.num)

#cost:100
set.seed(2)
grid100 <- data.frame(.C=100,.sigma=0.14)
tune.svm100 <- train(f,data = TrainingSet.Norm,method='svmRadial',scaled=FALSE,trControl=ctrl2,tuneGrid=grid100)
pred.svm100 <- predict(tune.svm100,ValidationSet.Norm,type='prob')
roc.svm100 <- roc(pred.svm100$X.0,response = ValidationSet.Norm$salary.num)
roc.svm100$auc
df.svm100 <- data.frame(prob=pred.svm100$X.0,COST='100 / auc = 0.882',obs=ValidationSet.Norm$salary.num)

#cost:1000
set.seed(2)
grid1000 <- data.frame(.C=1000,.sigma=0.14)
tune.svm1000 <- train(f,data = TrainingSet.Norm,method='svmRadial',scaled=FALSE,trControl=ctrl2,tuneGrid=grid1000)
pred.svm1000 <- predict(tune.svm1000,ValidationSet.Norm,type='prob')
roc.svm1000 <- roc(pred.svm1000$X.0,response = ValidationSet.Norm$salary.num)
roc.svm1000$auc
df.svm1000 <- data.frame(prob=pred.svm1000$X.0,COST='1000 / auc = 0.880',obs=ValidationSet.Norm$salary.num)

# Spot checking the importance of the predictors on in the model, which appears to be identical to the descriptive tree's nodes:
varImp(tune.svm1000)

svmAll <- rbind(df.svm1000,df.svm100,df.svm10,df.svm1,df.svm0.1,df.svm0.01)
svmAll <- rbind(df.svm0.01,df.svm0.1,df.svm1,df.svm10,df.svm100,df.svm1000)
rocplot <- ggplot(data = svmAll,aes(d=obs,m=1-prob,color=COST))
rocplot+geom_roc()+geom_abline(aes(intercept=0,slope=1),linetype='dashed')+theme_minimal()+guides(color=guide_legend(keywidth=0.3,keyheight=0.6, default.unit="inch"))+theme(legend.text = element_text(size = 16),legend.title = element_text(size = 18))

###KNN:

ctrlKnn <- trainControl(method = 'none',classProbs = TRUE,summaryFunction = twoClassSummary,savePredictions = TRUE)

set.seed(2)
Kgrid3 <- data.frame(.k=3)
KnnFit3 <- train(f,data = TrainingSet.Norm,method='knn',trControl=ctrlKnn,tuneGrid=Kgrid3)
KnnPred3 <- predict(KnnFit3,ValidationSet.Norm,type="prob")
KnnROC3 <- roc(KnnPred3$X.0,response = ValidationSet.Norm$salary.num)
KnnROC3$auc
Knn3.df <- data.frame(prob=KnnPred3$X.0,obs=ValidationSet.Norm$salary.num,K= '3 / auc = 0.807')

set.seed(2)
Kgrid9 <- data.frame(.k=9)
KnnFit9 <- train(f,data = TrainingSet.Norm,method='knn',trControl=ctrlKnn,tuneGrid=Kgrid9)
KnnPred9 <- predict(KnnFit9,ValidationSet.Norm,type="prob")
KnnROC9 <- roc(KnnPred9$X.0,response = ValidationSet.Norm$salary.num)
KnnROC9$auc
Knn9.df <- data.frame(prob=KnnPred9$X.0,obs=ValidationSet.Norm$salary.num,K= '9 / auc = 0.849')

set.seed(2)
Kgrid13 <- data.frame(.k=13)
KnnFit13 <- train(f,data = TrainingSet.Norm,method='knn',trControl=ctrlKnn,tuneGrid=Kgrid13)
KnnPred13 <- predict(KnnFit13,ValidationSet.Norm,type="prob")
KnnROC13 <- roc(KnnPred13$X.0,response = ValidationSet.Norm$salary.num)
KnnROC13$auc
Knn13.df <- data.frame(prob=KnnPred13$X.0,obs=ValidationSet.Norm$salary.num,K= '13 / auc = 0.850')

set.seed(2)
Kgrid17 <- data.frame(.k=17)
KnnFit17 <- train(f,data = TrainingSet.Norm,method='knn',trControl=ctrlKnn,tuneGrid=Kgrid17)
KnnPred17 <- predict(KnnFit17,ValidationSet.Norm,type="prob")
KnnROC17 <- roc(KnnPred17$X.0,response = ValidationSet.Norm$salary.num)
KnnROC17$auc
Knn17.df <- data.frame(prob=KnnPred17$X.0,obs=ValidationSet.Norm$salary.num,K= '17 / auc = 0.851')

set.seed(2)
Kgrid21 <- data.frame(.k=21)
KnnFit21 <- train(f,data = TrainingSet.Norm,method='knn',trControl=ctrlKnn,tuneGrid=Kgrid21)
KnnPred21 <- predict(KnnFit21,ValidationSet.Norm,type="prob")
KnnROC21 <- roc(KnnPred21$X.0,response = ValidationSet.Norm$salary.num)
KnnROC21$auc
Knn21.df <- data.frame(prob=KnnPred21$X.0,obs=ValidationSet.Norm$salary.num,K= '21 / auc = 0.856')

Knn.All <- rbind(Knn3.df,Knn9.df,Knn13.df,Knn17.df,Knn21.df)
knnplot <- ggplot(data = Knn.All, aes(d=obs,m=1-prob,color=K))
knnplot+geom_roc()+geom_abline(aes(intercept=0,slope=1),linetype='dashed')+theme_minimal()+guides(color=guide_legend(keywidth=0.3,keyheight=0.6, default.unit="inch"))+theme(legend.text = element_text(size = 16),legend.title = element_text(size = 18))

##GLM - No parameter to tune!!
set.seed(2)
ctrlglm <- trainControl(method = 'none',classProbs = TRUE,summaryFunction = twoClassSummary,savePredictions = TRUE)
glmFit <- train(f,TrainingSet,method='glm',trControl = ctrlglm)
glmPred <- predict(glmFit,newdata=ValidationSet,type='prob')
glmROC <- roc(glmPred$X.0,response = ValidationSet$salary.num)
glmROC$auc
glm.df <- data.frame(prob=glmPred$X.0,obs=ValidationSet$salary.num)
glmPlot <- ggplot(data =glm.df,aes(d=obs,m=1-prob))
glmPlot+geom_roc(color='blue',show.legend=T)+geom_abline(aes(intercept=0,slope=1),linetype='dashed')+theme_minimal()+ggplot2::annotate(geom = 'text',label='auc = 0.874',x=0.75,y=0.30,size=9)+ggplot2::annotate('rect',x=0.75,y=0.30,xmin = 0.6,xmax = 0.9,ymin = 0.2,ymax = 0.4,alpha=0.2,color='blue')


##CART

CARTctrl <- trainControl(method = 'none',summaryFunction = twoClassSummary,savePredictions = TRUE,classProbs = TRUE)

set.seed(2)
CARTgrid1 <- data.frame(.mincriterion =0.01)
CARTFit1 <- train(f,data = TrainingSet,method='ctree',trControl=CARTctrl,tuneGrid=CARTgrid1)
CARTPredict1 <- predict(CARTFit1,newdata=ValidationSet,type="prob")
CARTROC1 <- roc(CARTPredict1$X.0,response = ValidationSet$salary.num)
CARTROC1$auc
CART.df1 <- data.frame(prob=CARTPredict1$X.0,obs=ValidationSet$salary.num,mincriterion='0.01 / auc = 0.863')

set.seed(2)
CARTgrid2 <- data.frame(.mincriterion =0.17)
CARTFit2 <- train(f,data = TrainingSet,method='ctree',trControl=CARTctrl,tuneGrid=CARTgrid2)
CARTPredict2 <- predict(CARTFit2,newdata=ValidationSet,type="prob")
CARTROC2 <- roc(CARTPredict2$X.0,response = ValidationSet$salary.num)
CARTROC2$auc
CART.df2 <- data.frame(prob=CARTPredict2$X.0,obs=ValidationSet$salary.num,mincriterion='0.17 / auc = 0.870')

set.seed(2)
CARTgrid3 <- data.frame(.mincriterion =0.33)
CARTFit3 <- train(f,data = TrainingSet,method='ctree',trControl=CARTctrl,tuneGrid=CARTgrid3)
CARTPredict3 <- predict(CARTFit3,newdata=ValidationSet,type="prob")
CARTROC3 <- roc(CARTPredict3$X.0,response = ValidationSet$salary.num)
CARTROC3$auc
CART.df3 <- data.frame(prob=CARTPredict3$X.0,obs=ValidationSet$salary.num,mincriterion='0.33 / auc = 0.874')

set.seed(2)
CARTgrid4 <- data.frame(.mincriterion =0.50)
CARTFit4 <- train(f,data = TrainingSet,method='ctree',trControl=CARTctrl,tuneGrid=CARTgrid4)
CARTPredict4 <- predict(CARTFit4,newdata=ValidationSet,type="prob")
CARTROC4 <- roc(CARTPredict4$X.0,response = ValidationSet$salary.num)
CARTROC4$auc
CART.df4 <- data.frame(prob=CARTPredict4$X.0,obs=ValidationSet$salary.num,mincriterion='0.50 / auc = 0.876')

set.seed(2)
CARTgrid5 <- data.frame(.mincriterion =0.66)
CARTFit5 <- train(f,data = TrainingSet,method='ctree',trControl=CARTctrl,tuneGrid=CARTgrid5)
CARTPredict5 <- predict(CARTFit5,newdata=ValidationSet,type="prob")
CARTROC5 <- roc(CARTPredict5$X.0,response = ValidationSet$salary.num)
CARTROC5$auc
CART.df5 <- data.frame(prob=CARTPredict5$X.0,obs=ValidationSet$salary.num,mincriterion='0.66 / auc = 0.876')

set.seed(2)
CARTgrid6 <- data.frame(.mincriterion =0.82)
CARTFit6 <- train(f,data = TrainingSet,method='ctree',trControl=CARTctrl,tuneGrid=CARTgrid6)
CARTPredict6 <- predict(CARTFit6,newdata=ValidationSet,type="prob")
CARTROC6 <- roc(CARTPredict6$X.0,response = ValidationSet$salary.num)
CARTROC6$auc
CART.df6 <- data.frame(prob=CARTPredict6$X.0,obs=ValidationSet$salary.num,mincriterion='0.82 / auc = 0.877')

set.seed(2)
CARTgrid7 <- data.frame(.mincriterion =0.99)
CARTFit7 <- train(f,data = TrainingSet,method='ctree',trControl=CARTctrl,tuneGrid=CARTgrid7)
CARTPredict7 <- predict(CARTFit7,newdata=ValidationSet,type="prob")
CARTROC7 <- roc(CARTPredict7$X.0,response = ValidationSet$salary.num)
CARTROC7$auc
CART.df7 <- data.frame(prob=CARTPredict7$X.0,obs=ValidationSet$salary.num,mincriterion='0.99 / auc = 0.874')

CARTAll <- rbind(CART.df1,CART.df2,CART.df3,CART.df4,CART.df5,CART.df6,CART.df7)
CARTPlot <- ggplot(data = CARTAll,aes(d=obs,m=1-prob,color=mincriterion))
CARTPlot+geom_roc()+geom_abline(aes(intercept=0,slope=1),linetype='dashed')+theme_minimal()+guides(color=guide_legend(keywidth=0.3,keyheight=0.6, default.unit="inch"))+theme(legend.text = element_text(size = 16),legend.title = element_text(size = 18))


###Random Forest:

RFctrl <- trainControl(method = 'none',classProbs = TRUE,savePredictions = TRUE,summaryFunction = twoClassSummary)

# mtry = 2
set.seed(2)
rfGrid2 <- data.frame(.mtry=2)
rfFit.2 <- train(f,data = TrainingSet,method='rf',trControl=RFctrl,tuneGrid=rfGrid2)
rfPredict.2 <- predict(rfFit.2,newdata=ValidationSet,type='prob')
rfROC2 <- roc(rfPredict.2$X.0,response = ValidationSet$salary.num)
rfROC2$auc
rfROC2.df <- data.frame(prob=rfPredict.2$X.0,obs=ValidationSet$salary.num,m='2 / auc = 0.862')

# mtry = 3
set.seed(2)
rfGrid3 <- data.frame(.mtry=3)
rfFit.3 <- train(f,data = TrainingSet,method='rf',trControl=RFctrl,tuneGrid=rfGrid3)
rfPredict.3 <- predict(rfFit.3,newdata=ValidationSet,type='prob')
rfROC3 <- roc(rfPredict.3$X.0,response = ValidationSet$salary.num)
rfROC3$auc
rfROC3.df <- data.frame(prob=rfPredict.3$X.0,obs=ValidationSet$salary.num,m='3 / auc = 0.853')



# mtry = 4
set.seed(2)
rfGrid4 <- data.frame(.mtry=4)
rfFit.4 <- train(f,data = TrainingSet,method='rf',trControl=RFctrl,tuneGrid=rfGrid4)
rfPredict.4 <- predict(rfFit.4,newdata=ValidationSet,type='prob')
rfROC4 <- roc(rfPredict.4$X.0,response = ValidationSet$salary.num)
rfROC4$auc
rfROC4.df <- data.frame(prob=rfPredict.4$X.0,obs=ValidationSet$salary.num,m='4 / auc = 0.846')


# mtry = 5
set.seed(2)
rfGrid5 <- data.frame(.mtry=5)
rfFit.5 <- train(f,data = TrainingSet,method='rf',trControl=RFctrl,tuneGrid=rfGrid5)
rfPredict.5 <- predict(rfFit.5,newdata=ValidationSet,type='prob')
rfROC5 <- roc(rfPredict.5$X.0,response = ValidationSet$salary.num)
rfROC5$auc
rfROC5.df <- data.frame(prob=rfPredict.5$X.0,obs=ValidationSet$salary.num,m='5 / auc = 0.834')


# mtry = 6
set.seed(2)
rfGrid6 <- data.frame(.mtry=6)
rfFit.6 <- train(f,data = TrainingSet,method='rf',trControl=RFctrl,tuneGrid=rfGrid6)
rfPredict.6 <- predict(rfFit.6,newdata=ValidationSet,type='prob')
rfROC6 <- roc(rfPredict.6$X.0,response = ValidationSet$salary.num)
rfROC6$auc
rfROC6.df <- data.frame(prob=rfPredict.6$X.0,obs=ValidationSet$salary.num,m='6 / auc = 0.833')

rfAll <- rbind(rfROC2.df,rfROC3.df,rfROC4.df,rfROC5.df,rfROC6.df)

rfPlot <- ggplot(data = rfAll, aes(d=obs, m=1-prob, color=m))
rfPlot+geom_roc()+geom_abline(aes(intercept=0,slope=1),linetype='dashed')+theme_minimal()+guides(color=guide_legend(keywidth=0.3,keyheight=0.6, default.unit="inch"))+theme(legend.text = element_text(size = 16),legend.title = element_text(size = 18))


## predicting the best model in each method on the unseen test set
# SVM
set.seed(2)
svmBest <- predict(tune.svm100,TestSet.Norm,type='prob')
svmBest.ROC <- roc(svmBest$X.0,response = TestSet.Norm$salary.num)
svmBest.ROC$auc
svmBest.df <- data.frame(prob=svmBest$X.0,obs=TestSet.Norm$salary.num,Method= 'SVM / auc = 0.876')

# KNN
set.seed(2)
KnnBest <- predict(KnnFit21,TestSet.Norm,type="prob")
KnnBest.ROC <- roc(KnnBest$X.0,response = TestSet.Norm$salary.num)
KnnBest.ROC$auc
KnnBest.df <- data.frame(prob=KnnBest$X.0,obs=TestSet.Norm$salary.num,Method= 'KNN / auc = 0.853')

#CART
set.seed(2)
CARTBest <- predict(CARTFit6,newdata=TestSet,type="prob")
CARTBest.ROC <- roc(CARTBest$X.0,response = TestSet$salary.num)
CARTBest.ROC$auc
CARTBest.df <- data.frame(prob=CARTBest$X.0,obs=TestSet$salary.num,Method= 'CART / auc = 0.878')

#GLM
set.seed(2)
GLMBest <- predict(glmFit,newdata=TestSet,type='prob')
GLMBest.ROC <- roc(GLMBest$X.0,response = TestSet$salary.num)
GLMBest.ROC$auc
GLMBest.df <- data.frame(prob=GLMBest$X.0,obs=TestSet$salary.num,Method= 'GLM / auc = 0.873')

rfBest <- predict(rfFit.2,newdata=TestSet,type='prob')
rfBest.ROC <- roc(rfBest$X.0,response = TestSet$salary.num)
rfBest.ROC$auc
rfBest.df <- data.frame(prob=rfBest$X.0,obs=TestSet$salary.num,Method= 'RF / auc = 0.862')

bestAll <- rbind(CARTBest.df, svmBest.df, GLMBest.df, rfBest.df, KnnBest.df)
bestPlot <- ggplot(data = bestAll, aes(d=obs, m= 1-prob, color=Method))
bestPlot + geom_roc()+geom_abline(aes(intercept=0,slope=1),linetype='dashed')+theme_minimal()+guides(color=guide_legend(keywidth=0.3,keyheight=0.6, default.unit="inch"))+theme(legend.text = element_text(size = 16),legend.title = element_text(size = 18))
